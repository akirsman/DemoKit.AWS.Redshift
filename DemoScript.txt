************************************************
*** GETTING STARTED LAB ************************
************************************************

[Create Redshift cluster with two nodes, with a IAM role that can access S3]

[Create an EC2 instance and install Aginity Workbench for Redshift]

create database tickit;
[optional: connect do the just created DB]

[Create user]
create user guest password 'Password!1';

[Optional - drop the user]
drop user guest;

[Create a table]
create table testtable (testcol int);
select * from pg_table_def where tablename = 'testtable';

[The encoding, distkey, and sortkey columns are used by Amazon Redshift for parallel processing. https://docs.aws.amazon.com/redshift/latest/dg/c_designing-tables-best-practices.html]
insert into testtable values (100);
select * from testtable;

[create tables and load data, https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-create-sample-db.html]

[Get custom role's arn with permissions to access S3, ex. "<ARN of a IAM role with S3 access permissions>"]
copy users from 's3://awssampledb/tickit/allusers_pipe.txt' credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' delimiter '|' region '<bucket's region>';

[load data]
copy users from 's3://awssampledb/tickit/allusers_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' region '<bucket's region>';

copy venue from 's3://awssampledb/tickit/venue_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' region '<bucket's region>';

copy category from 's3://awssampledb/tickit/category_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' region '<bucket's region>';

copy date from 's3://awssampledb/tickit/date2008_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' region '<bucket's region>';

copy event from 's3://awssampledb/tickit/allevents_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' timeformat 'YYYY-MM-DD HH:MI:SS' region '<bucket's region>';

copy listing from 's3://awssampledb/tickit/listings_pipe.txt' 
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>' 
delimiter '|' region '<bucket's region>';

copy sales from 's3://awssampledb/tickit/sales_tab.txt'
credentials 'aws_iam_role=<ARN of a IAM role with S3 access permissions>'
delimiter '\t' timeformat 'MM/DD/YYYY HH:MI:SS' region '<bucket's region>';

[query data]
-- Get definition for the sales table.
SELECT *    
FROM pg_table_def    
WHERE tablename = 'sales';    

-- Find total sales on a given calendar date.
SELECT sum(qtysold) 
FROM   sales, date 
WHERE  sales.dateid = date.dateid 
AND    caldate = '2008-01-05';

-- Find top 10 buyers by quantity.
SELECT firstname, lastname, total_quantity 
FROM   (SELECT buyerid, sum(qtysold) total_quantity
        FROM  sales
        GROUP BY buyerid
        ORDER BY total_quantity desc limit 10) Q, users
WHERE Q.buyerid = userid
ORDER BY Q.total_quantity desc;

-- Find events in the 99.9 percentile in terms of all time gross sales.
SELECT eventname, total_price 
FROM  (SELECT eventid, total_price, ntile(1000) over(order by total_price desc) as percentile 
       FROM (SELECT eventid, sum(pricepaid) total_price
             FROM   sales
             GROUP BY eventid)) Q, event E
       WHERE Q.eventid = E.eventid
       AND percentile = 1
ORDER BY total_price desc;

[Go the Amazon Redshift console to review the queries you executed. The Queries tab shows a list of queries that you executed over a time period you specify.]

[View a List of Table Names]
select distinct(tablename) from pg_table_def where schemaname = 'public'; 

[View users]
select * from pg_user;

[View recent queries]
select query, pid, elapsed, substring from svl_qlog
where userid = 100
order by starttime desc
limit 5;

[Drop database]
drop database tickit;

[Delete the cluster]

************************************************
*** TUNING LAB *********************************
************************************************

[Create Tables]
CREATE TABLE part 
(
  p_partkey     INTEGER NOT NULL,
  p_name        VARCHAR(22) NOT NULL,
  p_mfgr        VARCHAR(6) NOT NULL,
  p_category    VARCHAR(7) NOT NULL,
  p_brand1      VARCHAR(9) NOT NULL,
  p_color       VARCHAR(11) NOT NULL,
  p_type        VARCHAR(25) NOT NULL,
  p_size        INTEGER NOT NULL,
  p_container   VARCHAR(10) NOT NULL
);

CREATE TABLE supplier 
(
  s_suppkey   INTEGER NOT NULL,
  s_name      VARCHAR(25) NOT NULL,
  s_address   VARCHAR(25) NOT NULL,
  s_city      VARCHAR(10) NOT NULL,
  s_nation    VARCHAR(15) NOT NULL,
  s_region    VARCHAR(12) NOT NULL,
  s_phone     VARCHAR(15) NOT NULL
);

CREATE TABLE customer 
(
  c_custkey      INTEGER NOT NULL,
  c_name         VARCHAR(25) NOT NULL,
  c_address      VARCHAR(25) NOT NULL,
  c_city         VARCHAR(10) NOT NULL,
  c_nation       VARCHAR(15) NOT NULL,
  c_region       VARCHAR(12) NOT NULL,
  c_phone        VARCHAR(15) NOT NULL,
  c_mktsegment   VARCHAR(10) NOT NULL
);

CREATE TABLE dwdate 
(
  d_datekey            INTEGER NOT NULL,
  d_date               VARCHAR(19) NOT NULL,
  d_dayofweek          VARCHAR(10) NOT NULL,
  d_month              VARCHAR(10) NOT NULL,
  d_year               INTEGER NOT NULL,
  d_yearmonthnum       INTEGER NOT NULL,
  d_yearmonth          VARCHAR(8) NOT NULL,
  d_daynuminweek       INTEGER NOT NULL,
  d_daynuminmonth      INTEGER NOT NULL,
  d_daynuminyear       INTEGER NOT NULL,
  d_monthnuminyear     INTEGER NOT NULL,
  d_weeknuminyear      INTEGER NOT NULL,
  d_sellingseason      VARCHAR(13) NOT NULL,
  d_lastdayinweekfl    VARCHAR(1) NOT NULL,
  d_lastdayinmonthfl   VARCHAR(1) NOT NULL,
  d_holidayfl          VARCHAR(1) NOT NULL,
  d_weekdayfl          VARCHAR(1) NOT NULL
);
CREATE TABLE lineorder 
(
  lo_orderkey          INTEGER NOT NULL,
  lo_linenumber        INTEGER NOT NULL,
  lo_custkey           INTEGER NOT NULL,
  lo_partkey           INTEGER NOT NULL,
  lo_suppkey           INTEGER NOT NULL,
  lo_orderdate         INTEGER NOT NULL,
  lo_orderpriority     VARCHAR(15) NOT NULL,
  lo_shippriority      VARCHAR(1) NOT NULL,
  lo_quantity          INTEGER NOT NULL,
  lo_extendedprice     INTEGER NOT NULL,
  lo_ordertotalprice   INTEGER NOT NULL,
  lo_discount          INTEGER NOT NULL,
  lo_revenue           INTEGER NOT NULL,
  lo_supplycost        INTEGER NOT NULL,
  lo_tax               INTEGER NOT NULL,
  lo_commitdate        INTEGER NOT NULL,
  lo_shipmode          VARCHAR(10) NOT NULL
);

[Load data - 15' aprox.]
copy customer from 's3://awssampledbuswest2/ssbgz/customer' 
credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>' 
gzip compupdate off region 'us-west-2';

copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate' 
credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>' 
gzip compupdate off region 'us-west-2';

copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder' 
credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>'
gzip compupdate off region 'us-west-2';

copy part from 's3://awssampledbuswest2/ssbgz/part' 
credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>'
gzip compupdate off region 'us-west-2';

copy supplier from 's3://awssampledbuswest2/ssbgz/supplier' 
credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>'
gzip compupdate off region 'us-west-2';

[Verify]
select count(*) from LINEORDER;
select count(*) from PART;
select count(*) from  CUSTOMER;
select count(*) from  SUPPLIER;
select count(*) from  DWDATE;

[Determine how many 1 MB blocks of disk space are used for each table]
select stv_tbl_perm.name as table, count(*) as mb
from stv_blocklist, stv_tbl_perm
where stv_blocklist.tbl = stv_tbl_perm.id
and stv_blocklist.slice = stv_tbl_perm.slice
and stv_tbl_perm.name in ('lineorder','part','customer','dwdate','supplier')
group by stv_tbl_perm.name
order by 1 asc;

[Disable result caching (of results in the leader node)]
set enable_result_cache_for_session to off;

[Run baseline queries (twice, record second run)]
-- Query 1
-- Restrictions on only one dimension. 
select sum(lo_extendedprice*lo_discount) as revenue
from lineorder, dwdate
where lo_orderdate = d_datekey
and d_year = 1997 
and lo_discount between 1 and 3 
and lo_quantity < 24;

-- Query 2
-- Restrictions on two dimensions
select sum(lo_revenue), d_year, p_brand1
from lineorder, dwdate, part, supplier
where lo_orderdate = d_datekey
and lo_partkey = p_partkey
and lo_suppkey = s_suppkey
and p_category = 'MFGR#12'
and s_region = 'AMERICA'
group by d_year, p_brand1
order by d_year, p_brand1;

-- Query 3
-- Drill down in time to just one month 
select c_city, s_city, d_year, sum(lo_revenue) as revenue 
from customer, lineorder, supplier, dwdate
where lo_custkey = c_custkey
and lo_suppkey = s_suppkey
and lo_orderdate = d_datekey
and (c_city='UNITED KI1' or
c_city='UNITED KI5')
and (s_city='UNITED KI1' or
s_city='UNITED KI5')
and d_yearmonth = 'Dec1997'
group by c_city, s_city, d_year
order by d_year asc, revenue desc;

[Analyze (explain) a query to determine the best distribution for each table. Look for labels that begin with DS_BCAST or DS_DIST labels]
explain
select sum(lo_revenue), d_year, p_brand1
from lineorder, dwdate, part, supplier
where lo_orderdate = d_datekey
and lo_partkey = p_partkey
and lo_suppkey = s_suppkey
and p_category = 'MFGR#12'
and s_region = 'AMERICA'
group by d_year, p_brand1
order by d_year, p_brand1;

[Set sort keys and distribution styles]
Table name	Sort Key	Distribution Style
LINEORDER	lo_orderdate	lo_partkey
PART		p_partkey	p_partkey
CUSTOMER	c_custkey	ALL
SUPPLIER	s_suppkey	ALL
DWDATE		d_datekey	ALL

[Analyze compression for an existing table; apply it to new table creation]
analyze compression lineorder;

[Recreate dataset with optimizations]
CREATE TABLE part2 (
  p_partkey     	integer     	not null sortkey distkey,
  p_name        	varchar(22) 	not null,
  p_mfgr        	varchar(6)      not null,
  p_category    	varchar(7)      not null,
  p_brand1      	varchar(9)      not null,
  p_color       	varchar(11) 	not null,
  p_type        	varchar(25) 	not null,
  p_size        	integer     	not null,
  p_container   	varchar(10)     not null
);

CREATE TABLE supplier2 (
  s_suppkey     	integer        not null sortkey,
  s_name        	varchar(25)    not null,
  s_address     	varchar(25)    not null,
  s_city        	varchar(10)    not null,
  s_nation      	varchar(15)    not null,
  s_region      	varchar(12)    not null,
  s_phone       	varchar(15)    not null)
diststyle all;

CREATE TABLE customer2 (
  c_custkey     	integer        not null sortkey,
  c_name        	varchar(25)    not null,
  c_address     	varchar(25)    not null,
  c_city        	varchar(10)    not null,
  c_nation      	varchar(15)    not null,
  c_region      	varchar(12)    not null,
  c_phone       	varchar(15)    not null,
  c_mktsegment      varchar(10)    not null)
diststyle all;

CREATE TABLE dwdate2 (
  d_datekey            integer       not null sortkey,
  d_date               varchar(19)   not null,
  d_dayofweek	      varchar(10)   not null,
  d_month      	    varchar(10)   not null,
  d_year               integer       not null,
  d_yearmonthnum       integer  	 not null,
  d_yearmonth          varchar(8)	not null,
  d_daynuminweek       integer       not null,
  d_daynuminmonth      integer       not null,
  d_daynuminyear       integer       not null,
  d_monthnuminyear     integer       not null,
  d_weeknuminyear      integer       not null,
  d_sellingseason      varchar(13)    not null,
  d_lastdayinweekfl    varchar(1)    not null,
  d_lastdayinmonthfl   varchar(1)    not null,
  d_holidayfl          varchar(1)    not null,
  d_weekdayfl          varchar(1)    not null)
diststyle all;

CREATE TABLE lineorder2 (
  lo_orderkey      	    integer     	not null encode delta32k,
  lo_linenumber        	integer     	not null encode zstd,
  lo_custkey           	integer     	not null encode zstd,
  lo_partkey           	integer     	not null distkey encode zstd,
  lo_suppkey           	integer     	not null encode zstd,
  lo_orderdate         	integer     	not null sortkey encode zstd,
  lo_orderpriority     	varchar(15)     not null encode bytedict,
  lo_shippriority      	varchar(1)      not null encode zstd,
  lo_quantity          	integer     	not null encode zstd,
  lo_extendedprice     	integer     	not null encode zstd,
  lo_ordertotalprice   	integer     	not null encode zstd,
  lo_discount          	integer     	not null encode zstd,
  lo_revenue           	integer     	not null encode zstd,
  lo_supplycost        	integer     	not null encode zstd,
  lo_tax               	integer     	not null encode zstd,
  lo_commitdate         integer         not null encode zstd,
  lo_shipmode          	varchar(10)     not null encode bytedict
);

[Insert same data from original tables into new ones]
insert into part2 select * from part;
insert into supplier2 select * from supplier;
insert into customer2 select * from customer;
insert into dwdate2 select * from dwdate;
insert into lineorder2 select * from lineorder;

[OR, if copying again from S3, run the copy commands but without the "compupdate off" from each COPY statement. This time, you will allow COPY to apply compression encodings.]

[Run queries against the recreated tables]
-- Query 1
-- Restrictions on only one dimension. 
select sum(lo_extendedprice*lo_discount) as revenue
from lineorder2, dwdate2
where lo_orderdate = d_datekey
and d_year = 1997 
and lo_discount between 1 and 3 
and lo_quantity < 24;

-- Query 2
-- Restrictions on two dimensions
select sum(lo_revenue), d_year, p_brand1
from lineorder2, dwdate2, part2, supplier2
where lo_orderdate = d_datekey
and lo_partkey = p_partkey
and lo_suppkey = s_suppkey
and p_category = 'MFGR#12'
and s_region = 'AMERICA'
group by d_year, p_brand1
order by d_year, p_brand1;

-- Query 3
-- Drill down in time to just one month 
select c_city, s_city, d_year, sum(lo_revenue) as revenue 
from customer2, lineorder2, supplier2, dwdate2
where lo_custkey = c_custkey
and lo_suppkey = s_suppkey
and lo_orderdate = d_datekey
and (c_city='UNITED KI1' or
c_city='UNITED KI5')
and (s_city='UNITED KI1' or
s_city='UNITED KI5')
and d_yearmonth = 'Dec1997'
group by c_city, s_city, d_year
order by d_year asc, revenue desc;

[Check storage usage]
select stv_tbl_perm.name as "table", count(*) as "blocks (mb)"
from stv_blocklist, stv_tbl_perm
where stv_blocklist.tbl = stv_tbl_perm.id
and stv_blocklist.slice = stv_tbl_perm.slice
and stv_tbl_perm.name in ('customer', 'part', 'supplier', 'dwdate', 'lineorder')
group by stv_tbl_perm.name
order by 1 asc;

select stv_tbl_perm.name as "table", count(*) as "blocks (mb)"
from stv_blocklist, stv_tbl_perm
where stv_blocklist.tbl = stv_tbl_perm.id
and stv_blocklist.slice = stv_tbl_perm.slice
and stv_tbl_perm.name in ('customer2', 'part2', 'supplier2', 'dwdate2', 'lineorder2')
group by stv_tbl_perm.name
order by 1 asc;

[Check distribution skew - is the distribution among slices even?]
select trim(name) as table, slice, sum(num_values) as rows, min(minvalue), max(maxvalue)
from svv_diskusage
where name in ('customer', 'part', 'supplier', 'dwdate', 'lineorder') 
and col =0
group by name, slice
order by name, slice;

select trim(name) as table, slice, sum(num_values) as rows, min(minvalue), max(maxvalue)
from svv_diskusage
where name in ('customer2', 'part2', 'supplier2', 'dwdate2', 'lineorder2') 
and col =0
group by name, slice
order by name, slice;

[Run explain for queries and check whether there's communication among nodes. If DS_BCAST_INNER labels have been replaced by DS_DIST_ALL_NONE and DS_DIST_NONE, it means that no redistribution was required for those steps, and the query should run much more quickly]
explain
select sum(lo_revenue), d_year, p_brand1
from lineorder, dwdate, part, supplier
where lo_orderdate = d_datekey
and lo_partkey = p_partkey
and lo_suppkey = s_suppkey
and p_category = 'MFGR#12'
and s_region = 'AMERICA'
group by d_year, p_brand1
order by d_year, p_brand1;

explain
select sum(lo_revenue), d_year, p_brand1
from lineorder2, dwdate2, part2, supplier2
where lo_orderdate = d_datekey
and lo_partkey = p_partkey
and lo_suppkey = s_suppkey
and p_category = 'MFGR#12'
and s_region = 'AMERICA'
group by d_year, p_brand1
order by d_year, p_brand1;

************************************************
*** SPECTRUM LAB *******************************
************************************************

[Copy data to a bucket in the same region of the Redshift cluster]
aws s3 cp s3://awssampledbuswest2/tickit/spectrum/sales/ . --recursive

[Create external schema]
create external schema spectrum 
from data catalog 
database 'spectrumdb' 
iam_role 'arn:aws:iam::209615642202:role/CustomRedshiftS3AccessRole'
create external database if not exists;

[Create external table]
create external table spectrum.sales(
salesid integer,
listid integer,
sellerid integer,
buyerid integer,
eventid integer,
dateid smallint,
qtysold smallint,
pricepaid decimal(8,2),
commission decimal(8,2),
saletime timestamp)
row format delimited
fields terminated by '\t'
stored as textfile
location 's3://redshiftdemoak/';

[Query table]
select count(*) from spectrum.sales;
